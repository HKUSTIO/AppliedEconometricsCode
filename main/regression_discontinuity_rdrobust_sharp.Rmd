---
title: "Regression Discontinuity"
subtitle: "Sharp RDD"
output: 
  html_document:
    css: style_do.css
    number_sections: yes
    toc: yes
    toc_depth: '3'
    toc_float: yes
    theme: "spacelab" #"default", "bootstrap", "cerulean", "cosmo", "darkly", "flatly",
                 # "journal", "lumen", "paper", "readable", "sandstone", "simplex",
                 # "spacelab", "united", "yeti"
    highlight: "pygments" #"default", "tango", "pygments", "kate", "monochrome",
                 # "espresso", "zenburn", "haddock", "textmate"
    df_print: paged
    code_folding: show
date: 'Last update: `r Sys.Date()`'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE, echo = TRUE, fig.align = "center")
library(AppliedEconometricsCode)
library(foreach)
library(magrittr)
library(ggplot2)
library(kableExtra)
library(modelsummary)
library(rdrobust)
color_main <- scales::viridis_pal(option = "C")(1)
```

Here, we implement the estimation method for sharp regression discontinuity design using the `rdrobust` package. The functions called from `AppliedEconometricsCode` are defined in `R/functions_rdrobust.R`. Below, we generate samples based on Lee (2008), set options for the `rdrobust` package, and explain the interpretation of the results. Additionally, we conduct a density test, which is the verification process for local randomization, based on the `rddensity` package.

# Lee (2008)

# Generating simulation data

## Setting constants and parameters

First, fix the seed and set the number of individuals `N`.

```{r}
set.seed(1)
N <- 500
```

## Generating data

Next, we generate sample for the RD design by approximating the conditional expectation function of potential outcomes as in Lee (2008). Following CCT (2014) and others, the score `s` is distributed as `2*Beta(2,4) - 1`. This distribution has a longer tail on the treatment side, resulting in more observations in the control group than in the treatment group, as shown below.

```{r}
plot <- 
  data.frame(
    x = 
      c(
        -1, 
        1
      )) %>%
  ggplot(
    aes(
      x = x
      )
    ) + 
  stat_function(
    fun = 
      function(x) {
        dbeta(
          x = (x + 1)/2, 
          shape1 = 2, 
          shape2 = 4
        )
      }
    ) + 
  labs(
    y = "Density"
  ) +
  theme_classic()
plot
```

The observed outcome variable is generated by adding normal distribution noise to a fifth-degree polynomial of the score, as specified in the `specify_mu_lee` function. This corresponds to the data for Figure 4 (a) in Lee (2008), where the dependent variable is the vote share, and the data is fitted with a fifth-degree polynomial limited to samples with a vote margin of less than 0.99 and more than -0.99.

```{r}
plot <- 
  data.frame(
    x = 
      c(
        -1, 
        1
      )
  ) %>%
  ggplot(
    aes(
      x = x
    )
  ) + 
  stat_function(
    fun = specify_mu_lee,
    geom = "point"
  ) + 
  labs(
    y = "Regression function",
    x = "Score"
  ) +
  theme_classic()
plot
```

We generate Lee data and call it `dgp_lee`.

```{r}
dgp_lee <- 
  generate_dgp_lee(
    N = N
  )
```

We calculate the simple average difference between the treatment and control groups as `0.63 - 0.26 = 0.37`. However, the true effect of comparing the left limit and the right limit around the score is `0.52 - 0.48 = 0.04`, which does not match the simple average difference. This is because the difference in simple averages is not a comparison in the neighborhood around the score threshold.

```{r}
mean_y <-
  dgp_lee %>%
    dplyr::group_by(d) %>%
    dplyr::summarize(
      mean_y = mean(y)
    ) %>%
  dplyr::pull(mean_y) 
mean_y  %>%
  kbl() %>%
  kable_styling()

lim_mean_y <-
  data.frame(
    d = c(
      FALSE, 
      TRUE
    ),
    mean_y = c(
      specify_mu_lee(
        s = -1.e-30
      ),
      specify_mu_lee(
        s = 0
      )
    )
  )
lim_mean_y %>%
  kbl() %>%
  kable_styling()
```

# Analysis

## Estmiating with `rdrobust` package

By specifying the outcome variable `y` and the score variable `x` to the `rdrobust` function, a list of results can be obtained. One of the current inconveniences of `rdrobust` is that it does not allow for formulation using formulas like other regression analysis packages.

```{r}
result <- 
  rdrobust::rdrobust(
    y = dgp_lee$y,
    x = dgp_lee$s
  )
```

The estimation results are displayed as text. One inconvenience is that it does not support reporting through `modelsummary` or similar functionalities.
```{r}
summary(result)
```

When no options are specified during estimation, only the conventional estimates and standard errors, as well as robust standard errors for the asymptotic bias, are output. On the other hand, if the option `all = TRUE` is passed as shown below, bias-corrected estimates are also output together. The standard errors output are the same for both conventional and bias-corrected rows, and the estimates are the same for both bias-corrected and robust rows.

```{r}
result <- 
  rdrobust::rdrobust(
    y = dgp_lee$y,
    x = dgp_lee$s, 
    all = TRUE
  )
summary(result)
```

Additionally, by default, the optimal bandwidth is chosen to minimize the estimated mean squared error, and the kernel function selected is the triangular kernel.

In the example above, `rho = 0.645` is used, meaning that the bandwidth for bias correction chosen is significantly smaller than the bandwidth used for the final estimation. By specifying the option `rho = 1`, it is possible to request that the same bandwidth be used for both bias correction and the final estimation.

```{r}
result <- 
  rdrobust::rdrobust(
    y = dgp_lee$y,
    x = dgp_lee$s, 
    all = TRUE,
    rho = 1
  )
summary(result)
```

It is known that without going through the two stages of bias correction and estimation, if the bandwidth is chosen to be MSE optimal when conducting local quadratic regression, the numerical results can be equivalent. That is, by specifying local-quadratic with `p = 2` and using a common bandwidth as shown below, the estimation results appearing under `Conventional` will be identical to the `Robust` estimation results when `rho = 1`.

```{r}
result <- 
  rdrobust::rdrobust(
    y = dgp_lee$y,
    x = dgp_lee$s, 
    all = TRUE,
    p = 2,
    h = result$bws[1,1],
    b = result$bws[1,1]
  )
summary(result)
```


## Visualizing with `rdplot` function

In RD estimation, it is preferred to combine the plot of the actual estimates with plots of estimates fitted separately for the treatment and control groups, along with the plot of bin averages. This can be easily achieved using the `rdplot` function.

```{r}
rdrobust::rdplot(
  y = dgp_lee$y,
  x = dgp_lee$s
)
```

The method of binning can be changed by specifying the `binselect` option. Choices starting with `es` divide the x-axis into equal widths, while choices starting with `qs` divide it based on the quantiles of the score variable. The number of bins can be chosen by methods that minimize the mean squared error or approximate the variance of the raw data with the variance of the bin averages.

Here, both `es` and `qs` are methods that choose the number of bins to minimize the mean squared error across the entire support. `es` divides bins at equal intervals, which may present the risk of making the average of extremely few observations appear equivalent to the others. With `qs` bin selection, since the same number of observations falls into each bin, such problems can be avoided.

```{r}
rdrobust::rdplot(
  y = dgp_lee$y,
  x = dgp_lee$s,
  binselect = "es"
)
```

In fact, it can be observed that the positions of the bins in `qs` are concentrated around thresholds with many observations, compared to the positions of the bins in `es`.
For this reason, plots created using `qs` may not always be easy to read because they concentrate bins in areas with many observations, as mentioned below. Therefore, while referring to the bin selection by `qs` for robustness checks, it might be considered to use the bin selection by `es` with attention to its limitations.

```{r}
rdrobust::rdplot(
  y = dgp_lee$y,
  x = dgp_lee$s,
  binselect = "qs"
)
```

Note that the default is `esmv`, which is a decision method that approximates the variance of the raw data with the variance of the bin averages in equal interval bins.

```{r}
rdrobust::rdplot(
  y = dgp_lee$y,
  x = dgp_lee$s
)
```
